{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf8033-6604-4e6f-8dd6-590735f79f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy.fft as fft\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6fe29-c2fb-4cda-93c7-a58926140844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function files\n",
    "import parameter_utils as pu\n",
    "import mt_utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec0b35-8f04-4b5d-b229-833b27ba0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98519f-2d99-45f5-9c7e-30a4d652e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67d584-c191-4c25-8d3b-cfc6a5c6a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import claspy\n",
    "from claspy.data_loader import load_tssb_dataset\n",
    "from claspy.data_loader import load_has_dataset\n",
    "from claspy.segmentation import BinaryClaSPSegmentation\n",
    "from claspy.tests.evaluation import covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef6fdc-f555-4e81-93a3-ffc67ed11cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tssb = load_tssb_dataset()\n",
    "hasc = load_has_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9303315-c1ca-4a25-a3c6-f4a3cc17b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared results\n",
    "tssb_res = pd.read_pickle('results/zwischenergebnisse/clasp_on_downsampled_TS_TSSB_origW.pkl')\n",
    "tssb_ds = pd.read_pickle('results/zwischenergebnisse/all_downsampled_TSSB.pkl')\n",
    "\n",
    "hasc_res = pd.read_pickle('results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_origW.pkl')\n",
    "hasc_ds = pd.read_pickle('results/zwischenergebnisse/all_downsampled_HASC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb077d-ba5e-49ed-9c05-423036769984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test compression = 0.5, obtained from 1_splitting\n",
    "cr = 0.5\n",
    "tssb_res_filtered = tssb_res[tssb_res['compression']==cr]\n",
    "hasc_res_filtered = hasc_res[hasc_res['compression']==cr]\n",
    "\n",
    "columns = ['upscaled_cps_lin', 'upscaled_cps_idx', 'score_lin', 'score_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036be3b9-f55a-4ee3-8cdc-d3b5d268556f",
   "metadata": {},
   "source": [
    "# Functions and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39f42a-d21e-4c85-9c8d-b902865a31c6",
   "metadata": {},
   "source": [
    "## Bucket Getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c18055-7c8d-45ff-a596-44f80de8b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_indizes(cp_list,ds_algo,cf,ts,downscaled):\n",
    "    indizes = []\n",
    "    for cp in cp_list:\n",
    "        indizes.append(define_bucket(cp, ds_algo, cf, ts, downscaled)[0])\n",
    "    return indizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b1689-57cc-4059-ab6a-ecff2f8ac545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_index_difference(indexlist1, indexlist2): \n",
    "    l1_sorted = sorted(indexlist1)\n",
    "    l2_sorted = sorted(indexlist2)\n",
    "    max_difference = 0\n",
    "    while l1_sorted and l2_sorted:\n",
    "        min_distance = float('inf')\n",
    "        best_pair = None\n",
    "        \n",
    "        for elem_l1 in l1_sorted:\n",
    "            for elem_l2 in l2_sorted:\n",
    "                distance = abs(elem_l1 - elem_l2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_pair = (elem_l1, elem_l2)\n",
    "        \n",
    "        difference = best_pair[0] - best_pair[1]\n",
    "        \n",
    "        if max_difference is None or abs(difference) > abs(max_difference):\n",
    "            max_difference = difference\n",
    "        \n",
    "        l1_sorted.remove(best_pair[0])\n",
    "        l2_sorted.remove(best_pair[1])\n",
    "        \n",
    "    return int(max_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81007a45-e462-4532-977f-3aff29ab6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bucket_index_differences(dataset,original):\n",
    "    df = dataset.copy()\n",
    "    df['max_index_diff']=None\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        indizes_ds = get_bucket_indizes(row.ds_predictions,row.algo,row.compression,original.iloc[row.orig_TS_ID].time_series,True)\n",
    "        indizes_orig = get_bucket_indizes(row.true_cps,row.algo,row.compression,original.iloc[row.orig_TS_ID].time_series,False)\n",
    "        max_diff = get_largest_index_difference(indizes_ds,indizes_orig)\n",
    "        df.at[index,'max_index_diff']=int(max_diff)\n",
    "    return df.astype({'max_index_diff': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6011a-f24e-458a-a6a0-10c1ef5f273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_bucket(cp,ds_algo,cf,ts,downscaled,bucket_range=0):\n",
    "    #all ts in multivariate have same length, so this can simply be done using any ts in the set\n",
    "    # B = bucket size\n",
    "    n = ts.shape[0]\n",
    "    match ds_algo:\n",
    "        case 'MinMax':\n",
    "            B = 2/cf\n",
    "            P = 2\n",
    "        case 'M4':\n",
    "            B = 4/cf\n",
    "            P = 4\n",
    "        case 'MinMaxLTTB':\n",
    "            B = int((n-2)/((cf*n)-2))\n",
    "            P = 1\n",
    "        case 'LTTB':\n",
    "            B = int((n-2)/((cf*n)-2))\n",
    "            P = 1\n",
    "        case 'LTD':\n",
    "            #bucket size is dynamic but mean must be the same as lttb bucket size\n",
    "            B = int((n-2)/((cf*n)-2))\n",
    "            P = 1\n",
    "        case 'EveryNth':\n",
    "            B = 1/cf\n",
    "            P = 1\n",
    "    if downscaled:\n",
    "        bucket_index = np.ceil(cp/P)\n",
    "    else:\n",
    "        bucket_index = np.ceil(cp/B)\n",
    "        \n",
    "    lbucket=bucket_index-bucket_range\n",
    "    ubucket=bucket_index+bucket_range\n",
    "    index_range = [int((lbucket-1)*B), int(ubucket*B)]\n",
    "    \n",
    "    # check lrange or rrange is out of bounds\n",
    "    if index_range[1] > ts.shape[0]:\n",
    "        index_range[1]=ts.shape[0]-1\n",
    "    if index_range[0]<0:\n",
    "        index_range[0]=0\n",
    "    # can happen with upper bound restriction\n",
    "    if index_range[0]>index_range[1]:\n",
    "        index_range[0]=int(index_range[1]-(bucket_range*B))\n",
    "        \n",
    "    return int(bucket_index), index_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1205d75-8c39-4551-831f-234f73b46b5f",
   "metadata": {},
   "source": [
    "## Level Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b026ec-e504-4e4a-8f00-792d3c34114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_cps_linear(ds_cps, cf):\n",
    "    return (ds_cps*(1/cf)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfb31f-4043-4b8d-8113-9314d7bb9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_cps_index(ds_cps,index_lists):\n",
    "    if index_lists.ndim==1:\n",
    "        out = index_lists[ds_cps]\n",
    "    else:\n",
    "        # use first three channels as hasc winners\n",
    "        channels = index_lists[:,:3]\n",
    "        cps = []\n",
    "        for i in range(channels.shape[1]):\n",
    "            channel = channels[:,i]\n",
    "            cps = np.union1d(cps, channel[ds_cps])\n",
    "        out = ut.prune_cps(cps)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98329ad0-9f12-4484-a638-4651652f122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_change_points_all(dataset, downsampled, original):\n",
    "    upscaling_scores = []\n",
    "\n",
    "    for index, row in tqdm(dataset.iterrows(), total=len(dataset), desc=\"Processing rows\"):\n",
    "        orig = original.iloc[row.orig_TS_ID]\n",
    "\n",
    "        if len(row.ds_predictions)==0:\n",
    "            u_cps_lin = []\n",
    "            u_cps_idx = []\n",
    "        else:\n",
    "            u_cps_lin = upscale_cps_linear(row.ds_predictions, row.compression)\n",
    "            index_lists = downsampled[(downsampled.Orig_TS_ID==row.orig_TS_ID) & (downsampled.DS_Algo==row.algo) & (downsampled.CF==row.compression)].DS_TS_index.values[0]\n",
    "            u_cps_idx = upscale_cps_index(row.ds_predictions, index_lists)\n",
    "    \n",
    "        score_lin = covering({0: orig.cps}, u_cps_lin, orig.time_series.shape[0])\n",
    "        score_idx = covering({0: orig.cps}, u_cps_idx, orig.time_series.shape[0])\n",
    "\n",
    "        upscaling_scores.append((u_cps_lin, u_cps_idx, score_lin, score_idx))\n",
    "        \n",
    "    return upscaling_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09294c18-87d5-46e9-9632-9c0d1133ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comparison_matrix_levelScaling(df):\n",
    "    mean_lin = np.mean(df['score_lin'])\n",
    "    median_lin = np.median(df['score_lin'])\n",
    "    std_lin = np.std(df['score_lin'])\n",
    "    \n",
    "    mean_idx = np.mean(df['score_idx'])\n",
    "    median_idx = np.median(df['score_idx'])\n",
    "    std_idx = np.std(df['score_idx'])\n",
    "    \n",
    "    lin_idx_agg = pd.DataFrame([[mean_lin, mean_idx], [median_lin, median_idx], [std_lin, std_idx]], \n",
    "                               columns=['Linear upscaling','Index upscaling'], \n",
    "                               index=['mean','median','std']\n",
    "                              )\n",
    "    lin_idx_agg['Diff'] = lin_idx_agg['Linear upscaling'] - lin_idx_agg['Index upscaling']\n",
    "    return lin_idx_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469f4b0-8a23-4fba-add7-a3a4585442bb",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152d695-4907-4ecd-81cd-fc6b08aa0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_features(ts,dcps,ds_algo,cf,w_size,bucket_range):\n",
    "    #get index interval for each cp (bucket)\n",
    "    global_w = w_size\n",
    "    ucps = []\n",
    "    for cp in dcps:\n",
    "        bucket_index, bucket = define_bucket(cp,ds_algo,cf,ts,True,bucket_range=bucket_range)\n",
    "        bucket[0] = max(bucket[0], w_size)          # Ensure enough room for a window before\n",
    "        bucket[1] = min(bucket[1], len(ts) - w_size - 1)  # Ensure enough room for a window after\n",
    "        bucket_size = bucket[1]-bucket[0]\n",
    "        segment = np.arange(bucket[0],bucket[1]+1)\n",
    "        max_dist = -np.inf\n",
    "        i_max = None\n",
    "\n",
    "        for i in segment:\n",
    "            #for each point (index) calculate clasp similarity of w before p and after p\n",
    "            #highest dissimilarity is the cp\n",
    "            #define windows before and after index\n",
    "            \n",
    "            w_before = ts[i - w_size:i]\n",
    "            w_after = ts[i:i + w_size]           \n",
    "            \n",
    "            dist = ut.z_ED_fft(w_before,w_after)\n",
    "                \n",
    "            if dist > max_dist:\n",
    "                max_dist = dist\n",
    "                i_max = i\n",
    "        \n",
    "        ucps.append(i_max)    \n",
    "    return ucps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba70e53-369a-4a2d-83f9-c5cdf7e81ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_clasp(ts,dcps,ds_algo,cf,bucket_range):\n",
    "    ucps = []\n",
    "    for cp in dcps:\n",
    "        bucket_index, segment = define_bucket(cp,ds_algo,cf,ts,True,bucket_range=bucket_range)\n",
    "        ts_segment = ts[segment[0]:segment[1]]\n",
    "        curr_ucps = BinaryClaSPSegmentation().fit_predict(ts_segment)\n",
    "        if len(curr_ucps)==0:\n",
    "            ucps = np.union1d(ucps,[cp])\n",
    "        else:\n",
    "            ucps = np.union1d(ucps,curr_ucps)\n",
    "    ucps = ut.prune_cps(ucps)\n",
    "    return [int(cp) for cp in ucps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953569f-9fd3-47f3-9a92-8e728b67f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['maximum_diff', 'gradient', 'moving_avg', 'window_features', 'local_clasp']\n",
    "def fine_tune_ucps(method, ts, data_row):\n",
    "    ucps = data_row.upscaled_cps_lin\n",
    "    ft_cps = []\n",
    "    output = []\n",
    "    if ts.ndim == 1:\n",
    "        ts_arr = np.array([ts])\n",
    "    else:\n",
    "        ts_arr = np.transpose(ts)\n",
    "    runtime = time.process_time()\n",
    "    for ts in ts_arr:\n",
    "        if method == 'window_features':\n",
    "            w = pu.get_window_size_multivariate(ts) \n",
    "            output = window_features(ts,data_row.ds_predictions,data_row.algo,data_row.compression,w,abs(data_row.max_index_diff))\n",
    "        elif method == 'local_clasp':\n",
    "            output = local_clasp(ts,data_row.ds_predictions,data_row.algo,data_row.compression,abs(data_row.max_index_diff))\n",
    "        else:       \n",
    "            for i, cp in enumerate(ucps):\n",
    "                bucket_index, window = define_bucket(data_row.ds_predictions[i], data_row.algo, data_row.compression, ts,False,abs(data_row.max_index_diff))\n",
    "                window_size = window[1]-window[0]\n",
    "        \n",
    "                cp_segment = ts[window[0]:window[1]]\n",
    "                if method == 'maximum_diff':\n",
    "                    base = np.abs(np.diff(cp_segment))\n",
    "                elif method == 'gradient':\n",
    "                    base = np.abs(np.gradient(cp_segment))\n",
    "                elif method == 'moving_avg':\n",
    "                    smooth_series = pd.Series(cp_segment).rolling(window=window_size).mean()\n",
    "                    base = np.abs(cp_segment - smooth_series)\n",
    "                        \n",
    "                best_cp = window[0] + np.argmax(base)\n",
    "                ft_cps.append(best_cp)\n",
    "            \n",
    "            output = np.union1d(output,ft_cps)\n",
    "\n",
    "    if ts.ndim > 1:\n",
    "        output = ut.prune_cps(output)\n",
    "    runtime = time.process_time()-runtime\n",
    "    return [int(cp) for cp in output], runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b057bf-fa3c-437e-9eb2-1dd01f7debb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_cps_finetuned(data_ucps,data_orig,methods,quantils):\n",
    "    threshold = abs(min(quantils))\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fine_tuned_results = []\n",
    "    for index, row in tqdm(data_ucps.iterrows(), total=len(data_ucps), desc=\"Processing rows\"):\n",
    "        orig = data_orig.iloc[row.orig_TS_ID]\n",
    "        fine_tuned_results.append(('LinearScaling', row.score_lin, row.runtime))\n",
    "        for method in methods:\n",
    "            # only fine tune when individual bucket range exceeds threshold\n",
    "            if abs(row.max_index_diff)>threshold:\n",
    "                try:\n",
    "                    ft_cps, runtime = fine_tune_ucps(method,orig.time_series,row)\n",
    "                except:\n",
    "                    ft_cps, runtime = row.upscaled_cps_lin, row.runtime\n",
    "            else:\n",
    "                ft_cps, runtime = row.upscaled_cps_lin, row.runtime\n",
    "                \n",
    "            score = covering({0: orig.cps}, ft_cps, orig.time_series.shape[0])\n",
    "    \n",
    "            fine_tuned_results.append((method, score, runtime))\n",
    "    return fine_tuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e096303-8bad-466e-be44-5d48ab11c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comparison_matrix_fineTuning(df):\n",
    "    mean = df.groupby(by=['method']).mean().rename(columns={'score_lin': 'mean'})\n",
    "    median = df.groupby(by=['method']).median().rename(columns={'score_lin': 'median'})\n",
    "    std = df.groupby(by=['method']).std().rename(columns={'score_lin': 'std'})\n",
    "    \n",
    "    out = mean.merge(median, left_on='method', right_on='method')\n",
    "    out = out.merge(std, left_on='method', right_on='method')\n",
    "    out = out.transpose()\n",
    "    return out[['LinearScaling','maximum_diff', 'gradient', 'moving_avg', 'window_features', 'local_clasp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00497f1-41ba-4a13-84f1-421b60726017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_upscaled_and_score(input_df, original, method):\n",
    "    df = input_df.copy()\n",
    "    df['ucps']=None\n",
    "    df['score']=None\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        orig_ts = original.iloc[row.orig_TS_ID].time_series\n",
    "        if method == 'linear':\n",
    "            if len(row.ds_predictions)>0:\n",
    "                ucps = upscale_cps_linear(row.ds_predictions,row.compression)\n",
    "            else: \n",
    "                ucps=[]\n",
    "        elif method == 'window_features':\n",
    "            if orig_ts.ndim == 1:\n",
    "                ts_arr = np.array([orig_ts])\n",
    "            else:\n",
    "                ts_arr = np.transpose(orig_ts)\n",
    "\n",
    "            for ts in ts_arr:\n",
    "                w = pu.get_window_size_multivariate(ts)\n",
    "                indizes_ds = get_bucket_indizes(row.ds_predictions,row.algo,row.compression,orig_ts,True)\n",
    "                indizes_orig = get_bucket_indizes(row.true_cps,row.algo,row.compression,orig_ts,False)\n",
    "                max_diff = get_largest_index_difference(indizes_ds,indizes_orig)\n",
    "                ucps = window_features(ts,row.ds_predictions,row.algo,row.compression,w,bucket_range)\n",
    "            \n",
    "            if orig_ts.ndim > 1:\n",
    "                ucps = ut.prune_cps(ucps)            \n",
    "            \n",
    "        score = covering({0: row.true_cps}, ucps, orig_ts.shape[0])\n",
    "        \n",
    "        df.at[index,'ucps']=ucps\n",
    "        df.at[index,'score']=score\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823495eb-56d1-49b2-a892-43475e0b09c2",
   "metadata": {},
   "source": [
    "# Level Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d07de-35fb-476c-97e2-0cbda8d85dc2",
   "metadata": {},
   "source": [
    "## TSSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540076de-6b2e-4aa4-9594-9ae7f63c9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_tssb = upscale_change_points_all(tssb_res_filtered, tssb_ds, tssb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e18767-127a-412a-b560-407de73af6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_tssb_df = pd.DataFrame(upscaled_cps_tssb, columns=columns)\n",
    "upscaled_cps_tssb_df = pd.concat([tssb_res_filtered.reset_index(drop=True),upscaled_cps_tssb_df], axis=1)\n",
    "upscaled_cps_tssb_df.to_pickle(\"results/zwischenergebnisse/2a_upscaled_cps_level_tssb.pkl\")\n",
    "upscaled_cps_tssb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefd9cf-71b9-4307-b595-7f4bae657bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_scaling_scores_tssb = score_comparison_matrix_levelScaling(upscaled_cps_tssb_df)\n",
    "level_scaling_scores_tssb.to_excel(\"results/tables/summary_statistics_linear_index_upscaling_TSSB.xlsx\")\n",
    "level_scaling_scores_tssb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a677c-67e2-404b-8a95-67e7e9a0c6ab",
   "metadata": {},
   "source": [
    "## HASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd470a-77e8-428e-a2f4-ad6f1ccce17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_hasc = upscale_change_points_all(hasc_res_filtered, hasc_ds, hasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035451d5-85c9-4908-bdeb-03d15d44e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_hasc_df = pd.DataFrame(upscaled_cps_hasc, columns=columns)\n",
    "upscaled_cps_hasc_df = pd.concat([hasc_res_filtered.reset_index(drop=True),upscaled_cps_hasc_df], axis=1)\n",
    "upscaled_cps_hasc_df.to_pickle(\"results/zwischenergebnisse/2a_upscaled_cps_level_hasc.pkl\")\n",
    "upscaled_cps_hasc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97541e1e-40d6-4452-a2be-85322db0a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_scaling_scores_hasc = score_comparison_matrix_levelScaling(upscaled_cps_hasc_df)\n",
    "level_scaling_scores_hasc.to_excel(\"results/tables/summary_statistics_linear_index_upscaling_HASC.xlsx\")\n",
    "level_scaling_scores_hasc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699fc2d-48ed-494a-9efb-072c97c4cdde",
   "metadata": {},
   "source": [
    "# Bucket Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2d8cc-448c-431c-95cc-75fcf8e972ae",
   "metadata": {},
   "source": [
    "## TSSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad2fdf-7b1a-450a-90d9-10a08f09d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_tssb_df = add_bucket_index_differences(upscaled_cps_tssb_df,tssb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba2cbd-3d14-4bd4-80fd-1801a88ec876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=upscaled_cps_tssb_df.max_index_diff.values\n",
    "q1_tssb = int(np.percentile(data, 25))\n",
    "q3_tssb = int(np.percentile(data, 75))\n",
    "print(f\"Der Interquartilsbereich (IQR) liegt zwischen {q1_tssb} und {q3_tssb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a703d4c-f52b-4886-a697-706e3afb1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=upscaled_cps_tssb_df.max_index_diff)])\n",
    "fig.update_layout(\n",
    "    xaxis_title_text='Bucket index difference', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    height=400, \n",
    "    font=dict(\n",
    "            family=\"Arial\",\n",
    "            size=12,\n",
    "            color=\"black\"\n",
    "            ),\n",
    "    title=dict(\n",
    "            text=\"(a) TSSB\",\n",
    "            y=0.82,\n",
    "            x=0.06\n",
    "            )\n",
    ")\n",
    "fig.write_image(\"results/figures/distribution_bucket_index_diffs_TSSB.svg\", scale=1, width=1000, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3ead6-9534-46da-9843-35551cc40a29",
   "metadata": {},
   "source": [
    "## HASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e98dae-02da-4a0a-9379-279a51548d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cps_hasc_df = add_bucket_index_differences(upscaled_cps_hasc_df,hasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67833d1e-d6ff-4839-b526-e343a6e41e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=upscaled_cps_hasc_df.max_index_diff.values\n",
    "q1_hasc = int(np.percentile(data, 25))\n",
    "q3_hasc = int(np.percentile(data, 75))\n",
    "print(f\"Der Interquartilsbereich (IQR) liegt zwischen {q1_hasc} und {q3_hasc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f01ab-5e0a-46d5-a994-833dc8d1e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=upscaled_cps_hasc_df.max_index_diff)])\n",
    "fig.update_layout(\n",
    "    xaxis_title_text='Bucket index difference', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    height=400, \n",
    "    font=dict(\n",
    "            family=\"Arial\",\n",
    "            size=12,\n",
    "            color=\"black\"\n",
    "            ),\n",
    "    title=dict(\n",
    "            text=\"(b) HASC\",\n",
    "            y=0.82,\n",
    "            x=0.06\n",
    "            )\n",
    ")\n",
    "fig.write_image(\"results/figures/distribution_bucket_index_diffs_HASC.svg\", scale=1, width=1000, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05171a42-259e-4f94-af9c-dcf67f522e97",
   "metadata": {},
   "source": [
    "# Bucket Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956cde66-9962-4d41-8ba1-3cd42e855c1b",
   "metadata": {},
   "source": [
    "## TSSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba150ac4-7d8a-4610-bdbb-60801bbed599",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_upscaled_cps_tssb = upscale_cps_finetuned(upscaled_cps_tssb_df,tssb,methods,[q1_tssb,q3_tssb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42a812-efbe-4dc6-9f82-917c4907c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_upscaled_cps_tssb_df = pd.DataFrame(finetuned_upscaled_cps_tssb, columns=['method','score_lin','runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf930aa8-ee7c-48b4-84d6-44712114de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_score_sumMat_tssb = score_comparison_matrix_fineTuning(finetuned_upscaled_cps_tssb_df[['method','score_lin']])\n",
    "fine_tuned_score_sumMat_tssb.to_excel(\"results/tables/summary_statistics_UCPS_finetuning_TSSB.xlsx\")\n",
    "fine_tuned_score_sumMat_tssb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b669968-1103-4601-b578-a96f6f20c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add upscaled cps with best approach to dataframe and save (linear)\n",
    "tssb_res_dsW = pd.read_pickle('results/zwischenergebnisse/clasp_on_downsampled_TS_TSSB_dsW.pkl')\n",
    "tssb_res_ucps_dsW = add_upscaled_and_score(tssb_res_dsW, tssb, 'linear')\n",
    "tssb_res_ucps_dsW.to_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_TSSB_dsW_ucps.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c8abd-2504-477f-aea2-8e3a5a456576",
   "metadata": {},
   "source": [
    "## HASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7356bbe-2988-4be8-a74c-fcdb7a282ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_upscaled_cps_hasc = upscale_cps_finetuned(upscaled_cps_hasc_df,hasc,methods,[q1_hasc,q3_hasc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a3ff5-bcc9-49b5-8427-a0096be7f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_upscaled_cps_hasc_df = pd.DataFrame(finetuned_upscaled_cps_hasc, columns=['method','score_lin','runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabac60-6100-437c-b31e-053f9f87ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_score_sumMat_hasc = score_comparison_matrix_fineTuning(finetuned_upscaled_cps_hasc_df[['method','score_lin']])\n",
    "fine_tuned_score_sumMat_hasc.to_excel(\"results/tables/summary_statistics_UCPS_finetuning_HASC.xlsx\")\n",
    "fine_tuned_score_sumMat_hasc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe35c4-396c-4d29-bdfd-e5435345dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add upscaled cps with best approach to dataframe and save\n",
    "hasc_res_ucps = add_upscaled_and_score(hasc_res, hasc, 'linear')\n",
    "hasc_res_ucps.to_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_origW_ucps.pkl\")\n",
    "\n",
    "hasc_res_dsW = pd.read_pickle('results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_dsW.pkl')\n",
    "hasc_res_ucps_dsW = add_upscaled_and_score(hasc_res_dsW, hasc, 'linear')\n",
    "hasc_res_ucps_dsW.to_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_dsW_ucps.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
