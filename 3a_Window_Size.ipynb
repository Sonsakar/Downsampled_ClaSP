{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7b466d-d24c-4a27-acfa-30428378bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libs\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9dc933-87f5-4831-8f16-f30c52b71a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous datasets\n",
    "tssb_res_dsW = pd.read_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_TSSB_dsW_ucps.pkl\")\n",
    "tssb_res_origW = pd.read_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_TSSB_origW_ucps.pkl\")\n",
    "\n",
    "hasc_res_dsW = pd.read_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_dsW_ucps.pkl\")\n",
    "hasc_res_origW = pd.read_pickle(\"results/zwischenergebnisse/clasp_on_downsampled_TS_HASC_origW_ucps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4830ef42-bb0f-4223-a6aa-c108fb3bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comparison_matrix_w(df):\n",
    "    mean = df.groupby(by=['method']).mean().rename(columns={'score': 'mean'})\n",
    "    median = df.groupby(by=['method']).median().rename(columns={'score': 'median'})\n",
    "    std = df.groupby(by=['method']).std().rename(columns={'score': 'std'})\n",
    "    \n",
    "    out = mean.merge(median, left_on='method', right_on='method')\n",
    "    out = out.merge(std, left_on='method', right_on='method')\n",
    "    out = out.transpose()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2525727c-61f0-4084-a529-59aeb89fa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default cr 0.5\n",
    "cr = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749e037-43b6-4f0b-9262-be5ccf055222",
   "metadata": {},
   "source": [
    "# TSSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13b3e06-9965-4afd-b5e6-b9990e64172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tssb_res_dsW_filtered = tssb_res_dsW[tssb_res_dsW['compression']==cr].reset_index(drop=True)\n",
    "tssb_res_origW_filtered = tssb_res_origW[tssb_res_origW['compression']==cr].reset_index(drop=True)\n",
    "\n",
    "# filter samples\n",
    "tssb_res_dsW_filtered['method']='Downscaled SuSS'\n",
    "tssb_res_origW_filtered['method']='SuSS on downsampled TS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc1efe0-e956-4bb4-836e-7961daa27cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>Downscaled SuSS</th>\n",
       "      <th>SuSS on downsampled TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.713827</td>\n",
       "      <td>0.753702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.770432</td>\n",
       "      <td>0.804994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.266549</td>\n",
       "      <td>0.244451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method  Downscaled SuSS  SuSS on downsampled TS\n",
       "mean           0.713827                0.753702\n",
       "median         0.770432                0.804994\n",
       "std            0.266549                0.244451"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tssb_res_all = pd.concat([tssb_res_dsW_filtered,tssb_res_origW_filtered],axis=0).reset_index(drop=True)\n",
    "# compare mean scores and check which one is better\n",
    "window_sizes_SumMat_TSSB = score_comparison_matrix_w(tssb_res_all[['method','score']])\n",
    "window_sizes_SumMat_TSSB.to_excel(\"results/tables/summary_statistics_window_size_approaches_TSSB.xlsx\")\n",
    "window_sizes_SumMat_TSSB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ab022-f2c3-45d7-9159-bf69fbccb2b7",
   "metadata": {},
   "source": [
    "# HASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54383a6-5574-4658-a78f-2b527ac8610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasc_res_dsW_filtered =hasc_res_dsW[hasc_res_dsW['compression']==cr].reset_index(drop=True)\n",
    "hasc_res_origW_filtered = hasc_res_origW[hasc_res_origW['compression']==cr].reset_index(drop=True)\n",
    "\n",
    "hasc_res_dsW_filtered['method']='Downscaled SuSS'\n",
    "hasc_res_origW_filtered['method']='SuSS on downsampled TS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbdc631a-45b5-40d4-bb48-8f214b64375d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>Downscaled SuSS</th>\n",
       "      <th>SuSS on downsampled TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.716844</td>\n",
       "      <td>0.711923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.758134</td>\n",
       "      <td>0.746093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.229358</td>\n",
       "      <td>0.234787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method  Downscaled SuSS  SuSS on downsampled TS\n",
       "mean           0.716844                0.711923\n",
       "median         0.758134                0.746093\n",
       "std            0.229358                0.234787"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasc_res_all = pd.concat([hasc_res_dsW_filtered,hasc_res_origW_filtered],axis=0).reset_index(drop=True)\n",
    "# compare mean scores and check which one is better\n",
    "window_sizes_SumMat_HASC = score_comparison_matrix_w(hasc_res_all[['method','score']])\n",
    "window_sizes_SumMat_HASC.to_excel(\"results/tables/summary_statistics_window_size_approaches_HASC.xlsx\")\n",
    "window_sizes_SumMat_HASC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
